| Title                                                                                                                       | Date          | environment                       | agents                            | evaluation                               | other                | helper                                                                                                                                                                 |
|:----------------------------------------------------------------------------------------------------------------------------|:--------------|:----------------------------------|:----------------------------------|:-----------------------------------------|:---------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Communicative Agents for Software Development](https://arxiv.org/abs/2307.07924)                                           | July, 2023    | Collaboration, Embodied AI        | Prompting, More than three agents | Rule-based evaluation                    | No human involvement | [July, 2023] [Communicative Agents for Software Development](https://arxiv.org/abs/2307.07924), Chen Qian et al., arXiv                                                |
| [CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents](https://arxiv.org/abs/2310.17512) | October, 2023 | Pure Competition, Text and Speech | Prompting                         | Rule-based evaluation                    | No human involvement | [October, 2023] [CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents](https://arxiv.org/abs/2310.17512), Qinlin Zhao et al., arXiv |
| [SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents](https://openreview.net/forum?id=mM7VurbA4r)    | October, 2024 | Mixed Objectives, Text and Speech | Prompting, Two agents             | Model-based evaluation, Human evaluation | Human-in-loop        | [October, 2024] [SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents](https://openreview.net/forum?id=mM7VurbA4r), Xuhui Zhou et al., ICLR      |
| [Embodied LLM Agents Learn to Cooperate in Organized Teams](https://arxiv.org/abs/2403.12482)                               | March, 2024   | Collaboration, Embodied AI        | Prompting, More than three agents | Model-based evaluation, Human evaluation | Education            | [March, 2024] [Embodied LLM Agents Learn to Cooperate in Organized Teams](https://arxiv.org/abs/2403.12482), Xudong Guo et al., arXiv                                  |